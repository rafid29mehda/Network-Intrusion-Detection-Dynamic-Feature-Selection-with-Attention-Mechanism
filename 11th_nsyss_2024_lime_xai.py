# -*- coding: utf-8 -*-
"""11th NSysS 2024_LIME_XAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gif4nipQ1_24ZhODtV4DBq8NuaXzsLEB
"""

import time
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from lime.lime_tabular import LimeTabularExplainer
from collections import defaultdict
from memory_profiler import memory_usage

file_path = 'KDDTrain+_20Percent_modified.csv'
data = pd.read_csv(file_path)

label_encoders = {}
for col in ['Protocol_type', 'Service', 'Flag']:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

X = data.drop(['attack_type'], axis=1)
y = data['attack_type']

y_encoder = LabelEncoder()
y = y_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Step 6: Applying LIME for feature importance over multiple instances
explainer = LimeTabularExplainer(
    X_train.values,
    feature_names=X_train.columns,
    class_names=y_encoder.classes_,
    discretize_continuous=True,
    mode='classification'
)

# Step 7: Aggregate feature importance over the whole dataset (or a large sample)
n_samples = len(X_test)  # Use all instances from X_test or a sample
feature_importance = defaultdict(float)

# Set of valid feature names from the dataset
valid_feature_names = set(X_train.columns)

for i in range(n_samples):
    # Convert the instance back to a DataFrame with the same feature names
    instance = pd.DataFrame([X_test.iloc[i].values], columns=X_test.columns)

    # Generate LIME explanation
    exp = explainer.explain_instance(X_test.iloc[i].values, rf.predict_proba, num_features=len(X_train.columns))
    lime_explanation = exp.as_list()

    # Aggregate the importance of each feature
    for feature, importance in lime_explanation:
        # Extract only the feature name by splitting at the condition part and remove numeric-only conditions
        feature_name = feature.split(' ')[0]

        # Check if the feature name is in the valid feature names
        if feature_name in valid_feature_names:
            feature_importance[feature_name] += importance  # Keep positive/negative importance

# Define a function to run LIME explanation
def compute_lime_explanations():
    # Step 7: Aggregate feature importance over the whole dataset (or a large sample)
    n_samples = len(X_test)  # Use all instances from X_test or a sample
    feature_importance = defaultdict(float)

    # Set of valid feature names from the dataset
    valid_feature_names = set(X_train.columns)

    for i in range(n_samples):
        # Convert the instance back to a DataFrame with the same feature names
        instance = pd.DataFrame([X_test.iloc[i].values], columns=X_test.columns)

        # Generate LIME explanation
        exp = explainer.explain_instance(X_test.iloc[i].values, rf.predict_proba, num_features=len(X_train.columns))
        lime_explanation = exp.as_list()

        # Aggregate the importance of each feature
        for feature, importance in lime_explanation:
            # Extract only the feature name by splitting at the condition part and remove numeric-only conditions
            feature_name = feature.split(' ')[0]

            # Check if the feature name is in the valid feature names
            if feature_name in valid_feature_names:
                feature_importance[feature_name] += importance  # Keep positive/negative importance

    return feature_importance

# Measure memory usage and execution time for LIME explanations
start_time = time.time()
mem_usage = memory_usage(compute_lime_explanations)
lime_time = time.time() - start_time

print(f"Time taken for LIME to compute feature weights for {len(X_test)} instances: {lime_time:.2f} seconds")
print(f"Maximum memory usage during LIME computations: {max(mem_usage):.2f} MiB")

# Convert to DataFrame for better visualization
importance_df = pd.DataFrame(list(feature_importance.items()), columns=['Feature', 'Importance'])
importance_df.sort_values(by='Importance', ascending=False, inplace=True)

# Show the global feature importance with both positive and negative values
importance_df

